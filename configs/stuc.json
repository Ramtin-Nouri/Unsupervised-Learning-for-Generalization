{
    "gpus": 1,
    "epochs": 50,
    "unsupervised_epochs": 20,
    "batch_size": 2,
    "num_workers": 8,
    "use_joints": false,
    "model":{
    	"lstm_hidden_size": 512,
   	    "lstm_num_layers": 1,
    	"convlstm_layers": [16,16,16],
        "convolution_layers_decoder": [16,16,16],
	    "dropout_autoencoder":0
    },
    "dataset":{
	"num_training_samples_unsupervised":500
    }
}
