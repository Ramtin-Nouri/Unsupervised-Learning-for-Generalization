{
    "gpus": 1,
    "epochs": 50,
    "unsupervised_epochs": 10,
    "batch_size": 2,
    "num_workers": 8,
    "use_joints": false,
    "model":{
    	"lstm_hidden_size": 512,
   	    "lstm_num_layers": 1,
    	"convlstm_layers": [16,32,64],
        "convolution_layers_decoder": [64,32,16],
	    "dropout":0
    },
    "dataset":{
	"num_training_samples_unsupervised":500
    }
}
